{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Step 4: T·ªëi ∆∞u h√≥a MLP b·∫±ng GridSearchCV\n",
    "\n",
    " Ch·∫°y ri√™ng b∆∞·ªõc n√†y ƒë·ªÉ t√¨m m√¥ h√¨nh MLP t·ªët nh·∫•t cho t·∫≠p d·ªØ li·ªáu Iris."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 4.1: Chu·∫©n b·ªã d·ªØ li·ªáu (t·ª± ƒë·ªông t·∫°o l·∫°i iris_scaled.csv n·∫øu ch∆∞a c√≥)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ƒê√£ t√¨m th·∫•y file iris_scaled.csv.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "if not os.path.exists(\"iris_scaled.csv\"):\n",
    "    iris = load_iris()\n",
    "    data = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "    data['target'] = iris.target\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(data.drop('target', axis=1))\n",
    "    data_scaled = pd.DataFrame(X_scaled, columns=iris.feature_names)\n",
    "    data_scaled['target'] = data['target']\n",
    "\n",
    "    data_scaled.to_csv('iris_scaled.csv', index=False)\n",
    "    print(\"‚úÖ ƒê√£ t·∫°o file iris_scaled.csv t·ª´ d·ªØ li·ªáu g·ªëc.\")\n",
    "else:\n",
    "    print(\"‚úÖ ƒê√£ t√¨m th·∫•y file iris_scaled.csv.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 4.2: C√†i ƒë·∫∑t GridSearchCV v·ªõi pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "# ƒê·ªçc d·ªØ li·ªáu\n",
    "df = pd.read_csv(\"iris_scaled.csv\")\n",
    "X = df.drop(\"target\", axis=1)\n",
    "y = df[\"target\"]\n",
    "\n",
    "# T·∫°o pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # (d·ª± ph√≤ng n·∫øu ch·∫°y raw d·ªØ li·ªáu)\n",
    "    ('mlp', MLPClassifier(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "# L∆∞·ªõi si√™u tham s·ªë\n",
    "param_grid = {\n",
    "    'mlp__hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],\n",
    "    'mlp__activation': ['relu', 'tanh', 'logistic'],\n",
    "    'mlp__solver': ['adam', 'sgd'],\n",
    "    'mlp__alpha': [0.0001, 0.001, 0.01],\n",
    "    'mlp__learning_rate_init': [0.001, 0.01],\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 4.3: Ti·∫øn h√†nh GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ ƒêang hu·∫•n luy·ªán, vui l√≤ng ch·ªù...\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "‚úÖ Hu·∫•n luy·ªán ho√†n t·∫•t.\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=cv,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "print(\"‚è≥ ƒêang hu·∫•n luy·ªán, vui l√≤ng ch·ªù...\")\n",
    "grid_search.fit(X, y)\n",
    "print(\"‚úÖ Hu·∫•n luy·ªán ho√†n t·∫•t.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 4.4: L∆∞u v√† hi·ªÉn th·ªã k·∫øt qu·∫£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Best Parameters: {'mlp__activation': 'tanh', 'mlp__alpha': 0.0001, 'mlp__hidden_layer_sizes': (100, 50), 'mlp__learning_rate_init': 0.001, 'mlp__solver': 'adam'}\n",
      "üèÜ Best Accuracy: 97.33%\n"
     ]
    }
   ],
   "source": [
    "# L∆∞u m√¥ h√¨nh v√† k·∫øt qu·∫£\n",
    "joblib.dump(grid_search, \"mlp_gridsearch_model.pkl\")\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "results_df.to_csv(\"mlp_gridsearch_results.csv\", index=False)\n",
    "\n",
    "# In k·∫øt qu·∫£ t·ªët nh·∫•t\n",
    "print(\"üéØ Best Parameters:\", grid_search.best_params_)\n",
    "print(f\"üèÜ Best Accuracy: {grid_search.best_score_ * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
